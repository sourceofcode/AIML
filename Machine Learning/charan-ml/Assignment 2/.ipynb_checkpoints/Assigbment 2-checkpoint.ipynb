{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1\n",
    "Dataset: Pacific_train.csv and Pacific_test.csv\n",
    "Dataset Description:\n",
    "The NHC publishes the tropical cyclone historical database in a format known as HURDAT, short for HURricane DATabase. These databases (Atlantic HURDAT2 and NE/NC Pacific HURDAT2) contain six-hourly information on the location, maximum winds, central pressure, and (starting in 2004) size of all known tropical cyclones and subtropical cyclones.\n",
    "Columns:\n",
    "ID\n",
    "    Name\n",
    "    Date\n",
    "    Time\n",
    "    Event\n",
    "    Status\n",
    "    Latitude\n",
    "    Longitude\n",
    "    Maximum Wind\n",
    "    Minimum Pressure\n",
    "    Low Wind NE\n",
    "    Low Wind SE\n",
    "    Low Wind SW\n",
    "    Low Wind NW\n",
    "    Moderate Wind NE\n",
    "    Moderate Wind SE\n",
    "    Moderate Wind SW\n",
    "    Moderate Wind NW\n",
    "    High Wind NE\n",
    "    High Wind SE\n",
    "    High Wind SW\n",
    "    High Wind NW\n",
    " \n",
    "Problem Statement \n",
    " \n",
    "You are provided with two data sets “Pacific_train.csv” and “Pacific_test.csv” having hurricane and typhoon information.\n",
    "***Note: No train-test splitting should be done as test data is already provided***\n",
    "You are required to make a multi-class classification model where the target variable is “Status” to classify hurricanes and typhoons into the correct category.\n",
    " \n",
    "Carry out the following tasks and select the appropriate features and make classification models using the following algorithms having a 10-fold cross validation score : \n",
    "Decision Trees ( Applying different criterion and choosing the best )\n",
    "Random Forest\n",
    "Naive Bayes\n",
    "SupportVectorClassfier\n",
    " \n",
    "HINT: Use correlation to select the most appropriate features.\n",
    "The features [Maximum Wind, Minimum Pressure, Low Wind NE] can be used for the model fitting\n",
    "Write python functions for the following and compare the performance of algorithms used above: \n",
    "Recall\n",
    "Precision\n",
    "Accuracy\n",
    " \n",
    "The Recall, Precision is to be computed for each label and algorithm pair\n",
    " \n",
    "1. Which is the best model? \n",
    "Hint: Implement all the above-mentioned models and then calculate the value of recall, precision and accuracy of each of them to finally select the best model.\n",
    "NOTE: You MUST implement all the 4 models mentioned above in the question.\n",
    "NOTE: You must use the training dataset to train the model and the testing dataset to check the accuracy and confusion matrix.\n",
    "NOTE: Do not use any hyperparameters of any model.\n",
    "Training Data:---> res/training/Pacific_train.csv\n",
    "Test Data:----> res/validation/Pacific_test.csv        \n",
    "Final Output Sample:\n",
    "﻿\n",
    "\n",
    " \n",
    "NOTE: Let's say Naive Bayes Algorithm is the best algorithm for the above scenario with accuracy 0.7, then print GaussianNB(Name of Naive Bayes function in sklearn) and its respective accuracy score in a CSV file in the above-mentioned format.\n",
    " \n",
    "Output Format:\n",
    "Perform the above operations and write your output to a file named output.csv, which should be present at the location output/output.csv\n",
    "output.csv should contain the answer to each question on consecutive rows.\n",
    " \n",
    "***Note: Write the code only inside solution() function and do not pass any additional arguments. For predefined stub refer stub.py***\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Author :K venkata charan \n",
    "Phone :7382777766\n",
    "Email:kvenkatcharan@gmail.com\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold,cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('res/training/Pacific_train.csv')\n",
    "test=pd.read_csv('res/validation/Pacific_test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 999)\n",
    "pd.set_option('display.max_columns', 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold,cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
    "def solution():\n",
    "    train=pd.read_csv('res/training/Pacific_train.csv')\n",
    "    test=pd.read_csv('res/validation/Pacific_test.csv')\n",
    "    train.isnull().sum()\n",
    "    t_corr=train.corr() >0.95\n",
    "    t_corr.sum()>=12\n",
    "    X_train=train[['Maximum Wind','Minimum Pressure','Low Wind NE']]\n",
    "    X_test=test[['Maximum Wind','Minimum Pressure','Low Wind NE']]\n",
    "    y_train=train['Status']\n",
    "    y_test=test['Status']\n",
    "    models=[]\n",
    "    models.append(('DecisionTreeClassifier',DecisionTreeClassifier()))\n",
    "    models.append(('DecisionTreeClassifier_entropy',DecisionTreeClassifier(criterion=\"entropy\")))\n",
    "    models.append(('RandomForestClassifier',RandomForestClassifier()))\n",
    "    models.append(('SVC',SVC()))\n",
    "    models.append(('GaussianNB',GaussianNB()))\n",
    "    results=pd.DataFrame()\n",
    "    acc=[]\n",
    "    for name , model in models:\n",
    "        k_fold=KFold(n_splits=10)\n",
    "        cross_val_sc=cross_val_score(model,X_train,y_train,cv=k_fold,scoring='accuracy')\n",
    "        print('{} : accuracy:{}( standard deviation:{})'.format(name,cross_val_sc.mean(),cross_val_sc.std()))\n",
    "        model.fit(X_train,y_train)\n",
    "        y_pred1 = model.predict(X_test)\n",
    "        acc = accuracy_score(y_test, y_pred1)\n",
    "        prec = precision_score(y_test, y_pred1,average='micro')\n",
    "        rec = recall_score(y_test, y_pred1,average='micro')\n",
    "        f1 = f1_score(y_test, y_pred1,average='micro')\n",
    "        model_results = pd.DataFrame([[name, cross_val_sc.mean(),acc, prec, rec, f1]],\n",
    "                       columns = ['Model','cross_val_sc','Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
    "\n",
    "        results = results.append(model_results, ignore_index = True)\n",
    "    print(results)\n",
    "    max_ac=results.loc[results['cross_val_sc']==results['cross_val_sc'].max(),].values\n",
    "    result=[max_ac[0][0], np.round(max_ac[0][1],2)]\n",
    "    print(result)\n",
    "    result=pd.DataFrame(result)\n",
    "    #writing output to output.csv\n",
    "    result.to_csv('output/output.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sec technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "\n",
    "train=pd.read_csv('/data/training/Pacific_train.csv')\n",
    "test=pd.read_csv('/data/test/Pacific_test.csv')\n",
    "\n",
    "train['Status'].value_counts()\n",
    "test['Status'].value_counts()\n",
    "\n",
    "features=['Maximum Wind', 'Minimum Pressure', 'Low Wind NE',\n",
    "       'Low Wind SE', 'Low Wind SW', 'Low Wind NW', 'Moderate Wind NE',\n",
    "       'Moderate Wind SE', 'Moderate Wind SW', 'Moderate Wind NW',\n",
    "       'High Wind NE', 'High Wind SE', 'High Wind SW', 'High Wind NW']\n",
    "label='Status'\n",
    "\n",
    "sns.heatmap(train[features].corr())\n",
    "#Most of the features looks correlated so let's drop them \n",
    "features_selected=['Maximum Wind','Minimum Pressure','Low Wind NE']\n",
    "\n",
    "X_train=train[features_selected]\n",
    "y_train=train[label]\n",
    "\n",
    "#Decision Tree \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "clf_DT = DecisionTreeClassifier()\n",
    "\n",
    "clf_DT.fit(X_train,y_train)\n",
    "\n",
    "cross_val_score(clf_DT, X_train, y_train, cv=10).mean()\n",
    "\n",
    "#Random Forests \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "clf_RF = RandomForestClassifier(n_estimators=200)\n",
    "\n",
    "clf_RF.fit(X_train,y_train)\n",
    "\n",
    "cross_val_score(clf_RF, X_train, y_train, cv=10).mean()\n",
    "\n",
    "#Naive Bayes \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "clf_gnb = GaussianNB()\n",
    "\n",
    "clf_gnb.fit(X_train,y_train)\n",
    "\n",
    "cross_val_score(clf_gnb, X_train, y_train, cv=10).mean()\n",
    "\n",
    "#SVM\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "clf_svc = SVC(gamma='auto')\n",
    "\n",
    "clf_svc.fit(X_train,y_train)\n",
    "\n",
    "cross_val_score(clf_svc, X_train, y_train, cv=10).mean()\n",
    "\n",
    "X_test=test[features_selected]\n",
    "y_test=test[label]\n",
    "\n",
    "pred_DT=clf_DT.predict(X_test)\n",
    "pred_RF=clf_RF.predict(X_test)\n",
    "pred_NB=clf_gnb.predict(X_test)\n",
    "pred_SVC=clf_svc.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix_DT=confusion_matrix(y_test,pred_DT)\n",
    "confusion_matrix_RF=confusion_matrix(y_test,pred_RF)\n",
    "confusion_matrix_NB=confusion_matrix(y_test,pred_NB)\n",
    "confusion_matrix_SVC=confusion_matrix(y_test,pred_SVC)\n",
    "\n",
    "def precision(label, confusion_matrix):\n",
    "    col = confusion_matrix[:, label]\n",
    "    return confusion_matrix[label, label] / col.sum()\n",
    "    \n",
    "def recall(label, confusion_matrix):\n",
    "    row = confusion_matrix[label, :]\n",
    "    return confusion_matrix[label, label] / row.sum()\n",
    "\n",
    "def accuracy(confusion_matrix):\n",
    "    diagonal_sum = confusion_matrix.trace()\n",
    "    sum_of_all_elements = confusion_matrix.sum()\n",
    "    return diagonal_sum / sum_of_all_elements \n",
    "    \n",
    "all_models=[confusion_matrix_DT,confusion_matrix_RF,confusion_matrix_NB,confusion_matrix_SVC]\n",
    "algorithms=['Decision Trees','Random Forests','Naive Bayes','SupportVectorClassfier']\n",
    "for each in range(len(algorithms)):\n",
    "    print (\"For each in : \", algorithms[each])\n",
    "    print (\"Accuracy :\",accuracy(all_models[each]) )\n",
    "    print ()\n",
    "    print(\"label precision recall\")\n",
    "    for label in range(10):\n",
    "        print(f\"{label:5d} {precision(label, all_models[each]):9.3f} {recall(label, all_models[each]):6.3f}\")\n",
    "    print ()\n",
    "    print ()\n",
    "result=['RandomForestClassifier', 0.96]\n",
    "result=pd.DataFrame(result)\n",
    "#writing output to output.csv\n",
    "result.to_csv('/code/output/output.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
